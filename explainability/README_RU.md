# Система объяснимости Glass AI

## Обзор

Система объяснимости Glass AI предоставляет интерпретируемые объяснения для прогнозов моделей машинного обучения. Она помогает операторам понимать причины прогнозов ИИ, повышает доверие к системе и обеспечивает прозрачность принятия решений.

## Архитектура

```
Система объяснимости
├── Объяснитель моделей
│   ├── Интеграция с LSTM
│   ├── Интеграция с ViT
│   ├── Интеграция с GNN
│   └── Ансамблевый объяснитель
├── Атрибуция признаков
│   ├── SHAP значения
│   ├── LIME объяснения
│   └── Контрфактурный анализ
└── Визуализация объяснений
    ├── Графики важности
    ├── Тепловые карты
    └── Временные визуализации
```

## Основные компоненты

### 1. Объяснитель моделей (`model_explainer.py`)
Интегрированный объяснитель для всех моделей ИИ системы.

#### Особенности:
- **Интеграция с LSTM**: Объяснения для прогнозов временных рядов
- **Интеграция с ViT**: Объяснения для обнаружения дефектов
- **Интеграция с GNN**: Объяснения для анализа сети датчиков
- **Ансамблевый объяснитель**: Комбинированные объяснения для ансамблевых моделей

### 2. Атрибуция признаков (`feature_attribution.py`)
Вычисление вклада каждого признака в прогноз модели.

#### Особенности:
- **SHAP значения**: Теоретически обоснованные значения атрибуции
- **LIME объяснения**: Локально интерпретируемые объяснения
- **Контрфактурный анализ**: Генерация альтернативных сценариев

### 3. Визуализация объяснений
Интерактивная визуализация объяснений для лучшего понимания.

#### Особенности:
- **Графики важности**: Ранжирование признаков по значимости
- **Тепловые карты**: Визуализация влияния признаков
- **Временные визуализации**: Отображение важности во времени

## Методы объяснимости

### SHAP (SHapley Additive exPlanations)
Теоретически обоснованный подход к объяснению прогнозов моделей.

#### Принцип работы:
- **SHAP значения**: Распределение вклада предсказания между признаками
- **Аддитивность**: Сумма SHAP значений равна отклонению от базового значения
- **Консистентность**: Более важные признаки получают большие значения

#### Преимущества:
- **Теоретическая обоснованность**: Основан на теории игр
- **Консистентность**: Устойчивые объяснения
- **Глобальная и локальная интерпретация**: Объяснения для отдельных прогнозов и модели в целом

### LIME (Local Interpretable Model-agnostic Explanations)
Локально интерпретируемые объяснения для любых моделей.

#### Принцип работы:
- **Локальная аппроксимация**: Создание интерпретируемой модели вокруг прогноза
- **Взвешенные выборки**: Генерация синтетических примеров
- **Объяснение**: Коэффициенты линейной модели как объяснения

#### Преимущества:
- **Модельно-независимость**: Работает с любыми моделями
- **Локальная точность**: Точные объяснения в окрестности прогноза
- **Интерпретируемость**: Простые для понимания объяснения

### Контрфактурный анализ
Генерация альтернативных сценариев для понимания причинно-следственных связей.

#### Принцип работы:
- **Поиск альтернатив**: Определение минимальных изменений для другого результата
- **Ранжирование факторов**: Определение наиболее влиятельных признаков
- **Рекомендации**: Предложения по улучшению ситуации

## Интеграция с моделями

### LSTM объяснения
Объяснения для прогнозов временных рядов.

#### Особенности:
- **Временная важность**: SHAP значения для каждого временного шага
- **Признаковая важность**: Вклад каждого признака на каждом шаге
- **Визуализация внимания**: Отображение фокуса механизма внимания

#### Пример объяснения:
```
Прогноз: Вероятность трещин 85%
Объяснение:
- Температура t-1: +0.25
- Давление t-2: +0.18
- Скорость ленты t-3: -0.12
- Температура t-5: +0.31
Базовое значение: 0.15
```

### Vision Transformer объяснения
Объяснения для обнаружения дефектов на изображениях.

#### Особенности:
- **Пространственная важность**: Важность различных областей изображения
- **Признаковая важность**: Вклад визуальных признаков
- **Тепловые карты**: Визуализация важных областей

#### Пример объяснения:
```
Дефект: Пузырь в области (x=120, y=80)
Объяснение:
- Область 110-130 x 70-90: +0.42
- Область 100-110 x 60-70: +0.18
- Область 130-140 x 80-90: +0.25
Базовое значение: 0.05
```

### GNN объяснения
Объяснения для анализа сети датчиков.

#### Особенности:
- **Узловая важность**: Важность различных датчиков
- **Реберная важность**: Важность связей между датчиками
- **Пути влияния**: Цепочки влияния между датчиками

#### Пример объяснения:
```
Аномалия: Нестабильность сети датчиков
Объяснение:
- Датчик FURNACE_01: +0.35
- Датчик FORMING_03: +0.28
- Связь FURNACE_01→FORMING_03: +0.22
- Датчик BELT_SPEED_01: -0.15
Базовое значение: 0.10
```

## Ансамблевые объяснения

Комбинированные объяснения для ансамблевых моделей.

### Методы комбинирования:
- **Взвешенное усреднение**: Среднее SHAP значений с весами моделей
- **Мета-объяснение**: Использование мета-модели для объяснения ансамбля
- **Консенсус**: Поиск согласия между объяснениями разных моделей

### Пример ансамблевого объяснения:
```
Прогноз: Вероятность дефектов 78%
Объяснение:
- LSTM (вес 0.4): +0.25
- ViT (вес 0.35): +0.18
- GNN (вес 0.25): +0.12
Консолидированное объяснение: +0.55
Базовое значение: 0.23
```

## Визуализация объяснений

### Графики важности признаков
Ранжирование признаков по значимости.

#### Особенности:
- **Горизонтальные бары**: Визуализация значений SHAP
- **Цветовая кодировка**: Положительные/отрицательные вклады
- **Интерактивность**: Сортировка, фильтрация, детализация

### Тепловые карты
Визуализация пространственного влияния.

#### Особенности:
- **Overlay на изображениях**: Наложение тепловой карты на изображения
- **Градиент цвета**: Интенсивность влияния
- **Анимация**: Эволюция влияния во времени

### Временные визуализации
Отображение важности во времени.

#### Особенности:
- **Линейные графики**: Изменение важности признаков
- **Области**: Вклад каждого признака во времени
- **Анимация**: Динамическое отображение изменений

## API объяснимости

### Получение объяснений:
```
GET /api/explainability/prediction?model_name=lstm&prediction_id=12345
```

### Получение глобальных объяснений:
```
GET /api/explainability/global?model_name=ensemble
```

### Контрфактурный анализ:
```
POST /api/explainability/counterfactual
{
  "model_name": "lstm",
  "desired_outcome": 0.3,
  "features_to_vary": ["furnace_temp", "belt_speed"]
}
```

## Интеграция с другими модулями

### С моделями ИИ:
- **Регистрация моделей**: Интеграция с каждой моделью системы
- **Автоматические объяснения**: Генерация объяснений для каждого прогноза
- **Кэширование**: Сохранение объяснений для повторного использования

### С RL агентом:
- **Объяснения рекомендаций**: Причины рекомендаций RL агента
- **Доверие к действиям**: Повышение доверия к автономным действиям
- **Обратная связь**: Использование объяснений для улучшения политик

### С графом знаний:
- **Верификация объяснений**: Сопоставление объяснений с причинно-следственными связями
- **Уточнение графа**: Обновление графа на основе объяснений
- **Гибридные объяснения**: Комбинация статистических и причинных объяснений

## Производительность

### Время генерации объяснений:
- **LSTM**: ~15 мс
- **ViT**: ~25 мс
- **GNN**: ~10 мс
- **Ансамбль**: ~30 мс

### Требования к ресурсам:
- **CPU**: 1-2 ядра для генерации объяснений
- **RAM**: 1-2 ГБ для кэширования объяснений
- **GPU**: Опционально для ускорения вычислений

## Конфигурация

### Параметры объяснимости:
```json
{
  "shap": {
    "sample_size": 100,
    "link": "identity"
  },
  "lime": {
    "num_samples": 5000,
    "kernel_width": 0.75
  },
  "caching": {
    "enabled": true,
    "ttl_hours": 24
  }
}
```

## Безопасность

### Валидация запросов:
- **Проверка моделей**: Только зарегистрированные модели
- **Ограничение параметров**: Проверка входных параметров
- **Rate limiting**: Ограничение частоты запросов

### Защита данных:
- **Анонимизация**: Удаление чувствительных данных из объяснений
- **Шифрование**: TLS для передачи объяснений
- **Аудит**: Логирование запросов объяснений

## Тестирование

### Юнит-тесты:
```bash
pytest tests/explainability/
```

### Тесты интеграции:
- Тестирование взаимодействия с моделями ИИ
- Тестирование API эндпоинтов
- Тестирование визуализаций

### Тесты качества объяснений:
- **Согласованность**: Проверка стабильности объяснений
- **Точность**: Соответствие объяснений реальным влияниям
- **Интерпретируемость**: Понятность объяснений для пользователей

## Развертывание

### Локальное развертывание:
```bash
python -m explainability.model_explainer
```

### Docker развертывание:
```dockerfile
FROM python:3.8-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY explainability/ explainability/

CMD ["python", "-m", "explainability.model_explainer"]
```

## Мониторинг

### Метрики объяснимости:
- **Время генерации**: Латентность создания объяснений
- **Качество объяснений**: Метрики точности и согласованности
- **Использование**: Частота запросов объяснений
- **Кэширование**: Эффективность кэширования объяснений

### Логирование:
- **Запросы объяснений**: Все запросы к системе объяснимости
- **Результаты**: Сгенерированные объяснения
- **Ошибки**: Исключения и ошибки выполнения
- **Производительность**: Метрики времени выполнения

## Устранение неполадок

### Распространенные проблемы:

1. **Медленная генерация объяснений**:
   - Уменьшите размер выборки для SHAP/LIME
   - Включите кэширование объяснений
   - Оптимизируйте модели для объяснений

2. **Непонятные объяснения**:
   - Проверьте качество моделей
   - Убедитесь в корректности данных
   - Используйте несколько методов объяснимости

3. **Проблемы с визуализацией**:
   - Проверьте поддержку браузера
   - Убедитесь в наличии необходимых ресурсов
   - Проверьте настройки отображения

## Расширяемость

### Добавление новых методов объяснимости:
- **Интерфейс объяснителя**: Единый интерфейс для всех методов
- **Плагин-система**: Возможность добавления методов без изменения ядра
- **Конфигурация**: Настройка методов через конфигурационные файлы

### Интеграция с внешними системами:
- **BI системы**: Интеграция с системами бизнес-аналитики
- **Системы мониторинга**: Интеграция с системами наблюдения
- **Системы отчетности**: Автоматическая генерация отчетов

## Версионирование

### Управление версиями:
- **SemVer**: Семантическое версионирование методов объяснимости
- **Git tags**: Тегирование релизов
- **Changelog**: Журнал изменений

### Откат версий:
- **Сохранение старых версий**: Архивирование предыдущих реализаций
- **Совместимость**: Поддержка обратной совместимости
- **Миграции**: Скрипты обновления объяснений

## Логирование

### Уровни логирования:
- **DEBUG**: Подробная информация для диагностики
- **INFO**: Общая информация о работе системы
- **WARNING**: Предупреждения о потенциальных проблемах
- **ERROR**: Ошибки, требующие внимания
- **CRITICAL**: Критические ошибки, требующие немедленного вмешательства

### Структура логов:
- **Временные метки**: Точное время событий
- **Идентификаторы**: Уникальные ID объяснений
- **Контекст**: Информация о модели и прогнозе
- **Данные**: Параметры и результаты объяснений