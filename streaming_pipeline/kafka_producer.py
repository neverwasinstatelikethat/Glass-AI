"""
Kafka Producer –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç batch –æ—Ç–ø—Ä–∞–≤–∫—É, retry –ª–æ–≥–∏–∫—É –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
"""

import asyncio
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
from aiokafka import AIOKafkaProducer
from aiokafka.errors import KafkaError
import msgpack

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GlassProductionKafkaProducer:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π Kafka producer –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    # –¢–æ–ø–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    TOPICS = {
        "sensors_raw": "glass.sensors.raw",
        "sensors_processed": "glass.sensors.processed",
        "defects": "glass.defects",
        "predictions": "glass.predictions",
        "alerts": "glass.alerts",
        "recommendations": "glass.recommendations",
        "quality_metrics": "glass.quality.metrics"
    }
    
    def __init__(
        self,
        bootstrap_servers: str = "localhost:9093",
        use_msgpack: bool = False,
        enable_idempotence: bool = True,
        compression_type: str = "gzip"
    ):
        self.bootstrap_servers = bootstrap_servers
        self.use_msgpack = use_msgpack
        self.producer: Optional[AIOKafkaProducer] = None
        self.enable_idempotence = enable_idempotence
        self.compression_type = compression_type
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            "messages_sent": 0,
            "messages_failed": 0,
            "bytes_sent": 0
        }
    
    async def start(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫ producer"""
        try:
            # –í—ã–±–æ—Ä —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
            if self.use_msgpack:
                value_serializer = lambda v: msgpack.packb(v, use_bin_type=True)
            else:
                value_serializer = lambda v: json.dumps(v).encode('utf-8')
            
            self.producer = AIOKafkaProducer(
                bootstrap_servers=self.bootstrap_servers,
                value_serializer=value_serializer,
                key_serializer=lambda k: k.encode('utf-8') if k else None,
                compression_type=self.compression_type,
                enable_idempotence=self.enable_idempotence,
                acks='all',
                max_batch_size=16384,
                linger_ms=10,
                request_timeout_ms=30000,
                retry_backoff_ms=100,
                metadata_max_age_ms=30000  # Refresh metadata every 30 seconds

            )
            
            await self.producer.start()
            logger.info(f"‚úÖ Kafka Producer –∑–∞–ø—É—â–µ–Ω: {self.bootstrap_servers}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ Kafka Producer: {e}")
            # Set producer to None to indicate it's not available
            self.producer = None
            # Don't raise the exception, allow system to continue in simulated mode
            logger.info("üîÑ Kafka Producer will run in simulated mode (no Kafka connection)")    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ producer —Å flush –±—É—Ñ–µ—Ä–∞"""
        if self.producer:
            try:
                await self.producer.stop()
                logger.info(f"‚úÖ Producer –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {self.stats}")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ producer: {e}")
    
    async def send_sensor_data(
        self,
        data: Dict[str, Any],
        processed: bool = False
    ) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–∞—Ç—á–∏–∫–æ–≤"""
        topic = self.TOPICS["sensors_processed"] if processed else self.TOPICS["sensors_raw"]
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        enriched_data = {
            **data,
            "kafka_timestamp": datetime.utcnow().isoformat(),
            "data_type": "sensor_reading"
        }
        
        # –ö–ª—é—á –¥–ª—è –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ –ª–∏–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞)
        key = data.get("production_line", "unknown")
        
        return await self._send_message(topic, enriched_data, key)
    
    async def send_defect(
        self,
        defect_data: Dict[str, Any]
    ) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–µ—Ñ–µ–∫—Ç–µ"""
        topic = self.TOPICS["defects"]
        
        enriched_data = {
            **defect_data,
            "kafka_timestamp": datetime.utcnow().isoformat(),
            "data_type": "defect"
        }
        
        key = f"{defect_data.get('production_line', 'unknown')}_{defect_data.get('defect_type', 'unknown')}"
        
        return await self._send_message(topic, enriched_data, key)
    
    async def send_prediction(
        self,
        prediction_data: Dict[str, Any]
    ) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ –º–æ–¥–µ–ª–∏"""
        topic = self.TOPICS["predictions"]
        
        enriched_data = {
            **prediction_data,
            "kafka_timestamp": datetime.utcnow().isoformat(),
            "data_type": "prediction"
        }
        
        key = prediction_data.get("model_id", "unknown")
        
        return await self._send_message(topic, enriched_data, key)
    
    async def send_alert(
        self,
        alert_data: Dict[str, Any],
        priority: str = "MEDIUM"
    ) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª–µ—Ä—Ç–∞"""
        topic = self.TOPICS["alerts"]
        
        enriched_data = {
            **alert_data,
            "priority": priority,
            "kafka_timestamp": datetime.utcnow().isoformat(),
            "data_type": "alert"
        }
        
        key = f"{priority}_{alert_data.get('alert_type', 'unknown')}"
        
        return await self._send_message(topic, enriched_data, key)
    
    async def send_recommendation(
        self,
        recommendation_data: Dict[str, Any]
    ) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—É"""
        topic = self.TOPICS["recommendations"]
        
        enriched_data = {
            **recommendation_data,
            "kafka_timestamp": datetime.utcnow().isoformat(),
            "data_type": "recommendation"
        }
        
        key = recommendation_data.get("action_type", "unknown")
        
        return await self._send_message(topic, enriched_data, key)
    
    async def send_quality_metrics(
        self,
        metrics_data: Dict[str, Any]
    ) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
        topic = self.TOPICS["quality_metrics"]
        
        enriched_data = {
            **metrics_data,
            "kafka_timestamp": datetime.utcnow().isoformat(),
            "data_type": "quality_metrics"
        }
        
        key = metrics_data.get("production_line", "unknown")
        
        return await self._send_message(topic, enriched_data, key)
    
    async def _send_message(
        self,
        topic: str,
        data: Dict[str, Any],
        key: Optional[str] = None,
        headers: Optional[List] = None
    ) -> bool:
        """–ë–∞–∑–æ–≤–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å retry –ª–æ–≥–∏–∫–æ–π"""
        if not self.producer:
            # Kafka not available, simulate successful send for graceful degradation
            logger.debug(f"üîÑ Kafka not available, simulating successful send to {topic}")
            self.stats["messages_sent"] += 1
            self.stats["bytes_sent"] += len(str(data).encode('utf-8'))
            return True
        
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
                future = await self.producer.send(
                    topic=topic,
                    value=data,
                    key=key,
                    headers=headers
                )
                
                # –û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
                record_metadata = await future
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                self.stats["messages_sent"] += 1
                # Use getattr to safely access serialized_value_size with a default value
                serialized_size = getattr(record_metadata, 'serialized_value_size', len(str(data)))
                self.stats["bytes_sent"] += serialized_size
                
                logger.debug(
                    f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: topic={topic}, "
                    f"partition={record_metadata.partition}, "
                    f"offset={record_metadata.offset}"
                )
                
                return True
                
            except KafkaError as e:
                retry_count += 1
                self.stats["messages_failed"] += 1
                
                logger.warning(
                    f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ (–ø–æ–ø—ã—Ç–∫–∞ {retry_count}/{max_retries}): {e}"
                )
                
                if retry_count < max_retries:
                    await asyncio.sleep(0.5 * retry_count)
                else:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                    return False
                    
            except Exception as e:
                logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ: {e}")
                self.stats["messages_failed"] += 1
                return False
    
    async def send_batch(
        self,
        topic: str,
        messages: List[Dict[str, Any]],
        key_extractor: Optional[callable] = None
    ) -> int:
        """Batch –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π"""
        success_count = 0
        
        for msg in messages:
            key = key_extractor(msg) if key_extractor else None
            if await self._send_message(topic, msg, key):
                success_count += 1
        
        logger.info(
            f"üì¶ Batch –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {success_count}/{len(messages)} —É—Å–ø–µ—à–Ω–æ –≤ {topic}"
        )
        
        return success_count
    
    def get_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ producer"""
        return self.stats.copy()


class SensorDataGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–∞—Ç—á–∏–∫–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self, production_line: str = "Line_A"):
        self.production_line = production_line
        import random
        self.random = random
    
    def generate_sensor_reading(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –ø–æ–∫–∞–∑–∞–Ω–∏–π –¥–∞—Ç—á–∏–∫–æ–≤"""
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "production_line": self.production_line,
            "sensors": {
                "furnace": {
                    "temperature": 1500 + self.random.uniform(-50, 50),
                    "pressure": 15.0 + self.random.uniform(-2, 2),
                    "melt_level": 2500 + self.random.uniform(-100, 100),
                    "o2_percent": 5.0 + self.random.uniform(-0.5, 0.5),
                    "co2_percent": 10.0 + self.random.uniform(-1, 1)
                },
                "forming": {
                    "mold_temperature": 320 + self.random.uniform(-20, 20),
                    "pressure": 50 + self.random.uniform(-5, 5),
                    "belt_speed": 150 + self.random.uniform(-10, 10)
                },
                "annealing": {
                    "temperature": 600 + self.random.uniform(-30, 30)
                },
                "process": {
                    "batch_flow": 2000 + self.random.uniform(-200, 200)
                }
            },
            "quality": {
                "defect_count": self.random.randint(0, 5),
                "defect_types": self.random.sample(
                    ["crack", "bubble", "chip", "cloudiness", "deformation"],
                    k=self.random.randint(0, 3)
                )
            }
        }
    
    def generate_defect(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –¥–µ—Ñ–µ–∫—Ç–µ"""
        defect_types = ["crack", "bubble", "chip", "cloudiness", "deformation", 
                       "inclusion", "stress", "surface_defect"]
        
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "production_line": self.production_line,
            "defect_type": self.random.choice(defect_types),
            "severity": self.random.choice(["LOW", "MEDIUM", "HIGH", "CRITICAL"]),
            "position": {
                "x": self.random.uniform(0, 1000),
                "y": self.random.uniform(0, 500)
            },
            "size_mm": self.random.uniform(0.1, 10.0),
            "confidence": self.random.uniform(0.7, 0.99)
        }


async def main_example():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è producer"""
    
    producer = GlassProductionKafkaProducer()
    generator = SensorDataGenerator()
    
    try:
        await producer.start()
        
        logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ü–∏–∫–ª–µ
        for i in range(100):
            # –°–µ–Ω—Å–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            sensor_data = generator.generate_sensor_reading()
            await producer.send_sensor_data(sensor_data)
            
            # –ò–Ω–æ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–µ—Ñ–µ–∫—Ç
            if i % 10 == 0:
                defect_data = generator.generate_defect()
                await producer.send_defect(defect_data)
            
            # –ò–Ω–æ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–ª–µ—Ä—Ç
            if i % 20 == 0:
                alert_data = {
                    "alert_type": "high_temperature",
                    "message": "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –ø–µ—á–∏ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –Ω–æ—Ä–º—É",
                    "value": 1650,
                    "threshold": 1600
                }
                await producer.send_alert(alert_data, priority="HIGH")
            
            await asyncio.sleep(1)
        
        stats = producer.get_stats()
        logger.info(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ Ctrl+C")
    finally:
        await producer.stop()


if __name__ == "__main__":
    asyncio.run(main_example())