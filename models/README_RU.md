# Модели ИИ системы Glass AI

## Обзор

Каталог `models` содержит все модели искусственного интеллекта, используемые в системе предиктивной аналитики производства стекла. Эти модели обеспечивают прогнозирование дефектов, обнаружение аномалий и оптимизацию производственных параметров.

## Архитектура моделей

### 1. LSTM прогнозор (`lstm_predictor/`)
Модель на основе длинной краткосрочной памяти для прогнозирования временных рядов в производственном процессе.

#### Компоненты:
- **attention_lstm.py**: Многослойная LSTM с механизмом внимания
- **multi_horizon.py**: Прогнозирование на нескольких временных горизонтах
- **uncertainty_estimator.py**: Оценка неопределенности прогнозов
- **lstm_model.onnx**: Экспортированная модель ONNX для вывода на границе

#### Особенности:
- Многослойная архитектура (2-3 слоя LSTM)
- Механизмы внимания для фокусировки на важных временных точках
- Оценка доверительных интервалов для прогнозов
- Прогнозирование на горизонтах 15 мин, 1 час, 4 часа, 24 часа

### 2. Vision Transformer (`vision_transformer/`)
Архитектура трансформера для обнаружения дефектов на изображениях с камеры МИК-1.

#### Компоненты:
- **defect_detector.py**: Модель для обнаружения дефектов
- **feature_extractor.py**: Извлечение признаков из изображений
- **segmentation_model.py**: Сегментационная модель для точного определения местоположения дефектов
- **vit_model.onnx**: Экспортированная модель ONNX

#### Особенности:
- Обнаружение 12 типов дефектов стекла
- Сегментация изображений для точного определения границ дефектов
- Классификация дефектов с оценкой уверенности
- Интеграция с системой объяснимости

### 3. Графовая нейронная сеть (`gnn_sensor_network/`)
Графовые нейронные сети для анализа сети датчиков и обнаружения аномалий.

#### Компоненты:
- **gnn_model.py**: Основная модель GNN
- **attention_pooling.py**: Pooling с механизмом внимания
- **graph_builder.py**: Построение графов сенсорной сети
- **gnn_model.onnx**: Экспортированная модель ONNX

#### Особенности:
- Анализ взаимосвязей между датчиками
- Обнаружение аномалий в сети датчиков
- Адаптация топологии графа в реальном времени
- Pooling с механизмом внимания для фокусировки на важных узлах

### 4. Ансамбль моделей (`ensemble/`)
Методы объединения прогнозов от различных моделей для повышения точности.

#### Компоненты:
- **meta_learner.py**: Мета-обучение для комбинирования прогнозов
- **stacking_ensemble.py**: Стекинг моделей
- **weighted_voting.py**: Взвешенное голосование моделей

#### Особенности:
- Взвешенное объединение прогнозов LSTM, ViT и GNN
- Адаптивные веса на основе точности моделей
- Учет неопределенности при объединении
- Мета-обучение для оптимизации комбинирования

## Производительность моделей

### Требования к точности:
- **Точность прогноза**: >85% на 1 час вперед
- **Полнота (Recall)**: >90% (обнаружить реальные дефекты)
- **Точность (Precision)**: >80% (избежать ложных алертов)

### Время обучения:
- **LSTM**: 2-4 часа на одном GPU
- **Vision Transformer**: 4-6 часов на одном GPU
- **GNN**: 1-2 часа на одном GPU
- **Ансамбль**: 30-60 минут

### Задержка вывода:
- **LSTM**: ~30 мс
- **Vision Transformer**: ~50 мс
- **GNN**: ~20 мс
- **Ансамбль**: ~60 мс

## Оптимизация для вывода на границе

Все модели экспортируются в формат ONNX и оптимизируются для развертывания на устройствах NVIDIA Jetson:

- **ONNX Runtime**: Кросс-платформенный движок вывода
- **TensorRT**: Оптимизация для NVIDIA GPU
- **Quantization**: Квантование моделей для уменьшения размера
- **Pruning**: Обрезка моделей для повышения производительности

## Объяснимость моделей

Все модели интегрированы с системой объяснимости:

- **SHAP значения**: Для оценки вклада признаков
- **LIME объяснения**: Локально интерпретируемые объяснения
- **Контрфактуры**: Генерация альтернативных сценариев
- **Важность признаков**: Ранжирование признаков по значимости

## Непрерывное обучение

Модели поддерживают непрерывное обучение:

- **Буфер опыта**: Хранение последних 10,000 образцов
- **EWC регуляризация**: Предотвращение катастрофического забывания
- **MAS**: Memory-Aware Synapses для сохранения знаний
- **Адаптация**: Автоматическая адаптация к изменяющимся условиям

## Интеграция с другими компонентами

### С инжинирингом признаков:
- Используют признаки из `feature_engineering/`
- Получают входные данные в стандартизированном формате

### С цифровым двойником:
- Получают параметры из симуляций
- Предоставляют прогнозы для what-if анализа

### С агентом RL:
- Предоставляют прогнозы для оценки действий
- Используют рекомендации для обучения

## Обучение моделей

### Генерация синтетических данных:
```bash
python generate_synthetic_data.py
```

### Обучение всех моделей:
```bash
python train_models.py
```

### Генерация ONNX моделей:
```bash
python generate_models.py
```

## Мониторинг и метрики

### Метрики производительности:
- **Точность**: Доля правильных прогнозов
- **Полнота**: Доля обнаруженных дефектов
- **F1-мера**: Гармоническое среднее точности и полноты
- **AUC-ROC**: Площадь под ROC кривой

### Метрики калибровки:
- **ECE**: Ожидаемая калибровочная ошибка
- **MCE**: Максимальная калибровочная ошибка
- **NLL**: Отрицательное логарифмическое правдоподобие

## Версионирование моделей

Система использует MLflow для версионирования моделей:
- Автоматическое логирование параметров и метрик
- Сохранение артефактов обучения
- Возможность отката к предыдущим версиям
- Сравнение производительности версий

## Развертывание

### Локальное развертывание:
```bash
python -m models.lstm_predictor.attention_lstm
```

### Docker развертывание:
```bash
docker build -t glass-models .
docker run glass-models
```

### Развертывание на границе:
- Экспорт в ONNX
- Оптимизация с TensorRT
- Развертывание на NVIDIA Jetson

## Тестирование моделей

### Юнит-тесты:
```bash
pytest tests/models/
```

### Интеграционные тесты:
```bash
pytest tests/integration/test_models.py
```

### Тесты производительности:
```bash
pytest tests/performance/test_model_inference.py
```